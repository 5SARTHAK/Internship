{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4345c7fd",
   "metadata": {},
   "source": [
    "# 1) Write a python program to display all the header tags from wikipedia.org."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c3abe3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "source = requests.get(\"https://en.wikipedia.org/wiki/Main_Page\")\n",
    "source.raise_for_status()\n",
    "soup = BeautifulSoup(source.text,\"html.parser\")\n",
    "header = soup.find_all(['h1','h2','h3','h4'])\n",
    "for i in header:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8dea539",
   "metadata": {},
   "source": [
    "# 2) Write a python program to display IMDB’s Top rated 100 movies’ data (i.e. name, rating, year of release) and make data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "469cc531",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup as bs\n",
    "import requests as rq\n",
    "import pandas as pd\n",
    "\n",
    "url = 'https://www.imdb.com/chart/top/'\n",
    "page = rq.get(url)\n",
    "soup = bs(page.content, 'html.parser')\n",
    "scraped_movies = soup.find_all('td', class_=\"titleColumn\")\n",
    "movies = []\n",
    "for movie in scraped_movies:\n",
    "    movies.append(movie.get_text().replace('\\n', '').strip(' '))\n",
    "del movies[100:]\n",
    "scraped_ratings = soup.find_all('td', class_=\"ratingColumn imdbRating\")\n",
    "ratings = []\n",
    "for rating in scraped_ratings:\n",
    "    ratings.append(rating.get_text().replace('\\n', ''))\n",
    "del ratings[100:]\n",
    "scraped_years = soup.find_all('span', class_=\"secondaryInfo\")\n",
    "years = []\n",
    "for year in scraped_years:\n",
    "    years.append(year.get_text())\n",
    "del years[100:]\n",
    "data = pd.DataFrame()\n",
    "data['Movie Name'] = movies\n",
    "data['Rating'] = ratings\n",
    "data['Year of Release'] = years\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d8457a9",
   "metadata": {},
   "source": [
    "# 3) Write a python program to display IMDB’s Top rated 100 Indian movies’ data (i.e. name, rating, year of release) and make data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60526cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup as bs\n",
    "import requests as rq\n",
    "import pandas as pd\n",
    "\n",
    "url = 'https://www.imdb.com/india/top-rated-indian-movies/'\n",
    "page = rq.get(url)\n",
    "soup = bs(page.content,'html.parser')\n",
    "scraped_movies = soup.find_all('td', class_=\"titleColumn\")\n",
    "movies = []\n",
    "for movie in scraped_movies:\n",
    "    movies.append(movie.get_text().replace('\\n', '').strip(' '))\n",
    "scraped_ratings = soup.find_all('td', class_=\"ratingColumn imdbRating\")\n",
    "del movies[100:]\n",
    "ratings = []\n",
    "for rating in scraped_ratings:\n",
    "    ratings.append(rating.get_text().replace('\\n', ''))\n",
    "del ratings[100:]\n",
    "scraped_years = soup.find_all('span', class_=\"secondaryInfo\")\n",
    "years = []\n",
    "for year in scraped_years:\n",
    "    years.append(year.get_text())\n",
    "del years[100:]\n",
    "data = pd.DataFrame()\n",
    "data['Movie Name'] = movies\n",
    "data['Rating'] = ratings\n",
    "data['Year of Release'] = years\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eecd1c90",
   "metadata": {},
   "source": [
    "# 4) Write s python program to display list of respected former presidents of India(i.e. Name , Term of office) from https://presidentofindia.nic.in/former-presidents.htm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d1bd665",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup as bs\n",
    "import requests as rq\n",
    "import pandas as pd\n",
    "\n",
    "url = 'https://presidentofindia.nic.in/former-presidents.htm'\n",
    "page = rq.get(url)\n",
    "soup = bs(page.content, 'html.parser')\n",
    "scraped_names = soup.find_all('div', class_=\"presidentListing\")\n",
    "names = []\n",
    "for name in scraped_names:\n",
    "    names.append(name.find('h3').text.split('(')[0])\n",
    "scraped_tops = soup.find_all('div', class_=\"presidentListing\")\n",
    "tops = []\n",
    "for top in scraped_tops:\n",
    "    tops.append(top.find('p').text.split(':')[1])\n",
    "data = pd.DataFrame()\n",
    "data['Former Presidents'] = names\n",
    "data['Term of Office'] = tops\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6add23a6",
   "metadata": {},
   "source": [
    "# 5) Write a python program to scrape cricket rankings from icc-cricket.com. You have to scrape:\n",
    " # a) Top 10 ODI teams in men’s cricket along with the records for matches, points and rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb298a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup as bs\n",
    "import requests as rq\n",
    "import pandas as pd\n",
    "\n",
    "url = 'https://www.icc-cricket.com/rankings/mens/team-rankings/odi'\n",
    "page = rq.get(url)\n",
    "soup = bs(page.content, 'html.parser')\n",
    "scraped_teams = soup.find_all('span', class_=\"u-hide-phablet\")\n",
    "teams = []\n",
    "for team in scraped_teams:\n",
    "    teams.append(team.get_text())\n",
    "del teams[10:]\n",
    "matches = []\n",
    "scraped_matches = soup.find_all('td', class_=\"table-body__cell u-center-text\")\n",
    "for match in scraped_matches:\n",
    "    matches.append(match.get_text())\n",
    "del matches[1::2]\n",
    "del matches[9:]\n",
    "first_match = soup.find('td', class_=\"rankings-block__banner--matches\").get_text()\n",
    "matches.insert(0, first_match)\n",
    "points = []\n",
    "scraped_points = soup.find_all('td', class_=\"table-body__cell u-center-text\")\n",
    "for point in scraped_points:\n",
    "    points.append(point.get_text())\n",
    "del points[::2]\n",
    "del points[9:]\n",
    "first_point = soup.find('td', class_=\"rankings-block__banner--points\").get_text()\n",
    "points.insert(0, first_point)\n",
    "rating = []\n",
    "scraped_rating = soup.find_all('td', class_=\"table-body__cell u-text-right rating\")\n",
    "for rate in scraped_rating:\n",
    "    rating.append(rate.get_text())\n",
    "del rating[9:]\n",
    "first_rating = soup.find('td', class_=\"rankings-block__banner--rating u-text-right\").get_text().replace('\\n', '').strip(' ')\n",
    "rating.insert(0, first_rating)\n",
    "data = pd.DataFrame()\n",
    "data['Team'] = teams\n",
    "data['Matches'] = matches\n",
    "data['Points'] = points\n",
    "data['Rating'] = rating\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe84f000",
   "metadata": {},
   "source": [
    "# b) Top 10 ODI Batsmen along with the records of their team and rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b236f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup as bs\n",
    "import requests as rq\n",
    "import pandas as pd\n",
    "\n",
    "url = 'https://www.icc-cricket.com/rankings/mens/player-rankings/odi/batting'\n",
    "page = rq.get(url)\n",
    "soup = bs(page.content, 'html.parser')\n",
    "scraped_players = soup.find_all('td', class_=\"table-body__cell rankings-table__name name\")\n",
    "players = []\n",
    "for player in scraped_players:\n",
    "    players.append(player.get_text().replace('\\n', ''))\n",
    "del players[9:]\n",
    "first_player = soup.find('div', class_=\"rankings-block__banner--name-large\").get_text()\n",
    "players.insert(0, first_player)\n",
    "scraped_teams = soup.find_all('span', class_=\"table-body__logo-text\")\n",
    "teams = []\n",
    "for team in scraped_teams:\n",
    "    teams.append(team.get_text())\n",
    "del teams[9:]\n",
    "first_team = soup.find('div', class_=\"rankings-block__banner--nationality\").get_text().replace('\\n', '')\n",
    "teams.insert(0, first_team)\n",
    "scraped_rating = soup.find_all('td', class_=\"table-body__cell rating\")\n",
    "rating = []\n",
    "for rate in scraped_rating:\n",
    "    rating.append(rate.get_text())\n",
    "del rating[9:]\n",
    "first_rating = soup.find('div', class_=\"rankings-block__banner--rating\").get_text()\n",
    "rating.insert(0, first_rating)\n",
    "rating\n",
    "data = pd.DataFrame()\n",
    "data['Player'] = players\n",
    "data['Team'] = teams\n",
    "data['Rating'] = rating\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a2dda50",
   "metadata": {},
   "source": [
    "# c) Top 10 ODI bowlers along with the records of their team and rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bbfca85",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup as bs\n",
    "import requests as rq\n",
    "import pandas as pd\n",
    "\n",
    "url = 'https://www.icc-cricket.com/rankings/mens/player-rankings/odi/bowling'\n",
    "page = rq.get(url)\n",
    "soup = bs(page.content, 'html.parser')\n",
    "scraped_players = soup.find_all('td', class_=\"table-body__cell rankings-table__name name\")\n",
    "players = []\n",
    "for player in scraped_players:\n",
    "    players.append(player.get_text().replace('\\n', ''))\n",
    "del players[9:]\n",
    "first_player = soup.find('div', class_=\"rankings-block__banner--name-large\").get_text()\n",
    "players.insert(0, first_player)\n",
    "scraped_teams = soup.find_all('span', class_=\"table-body__logo-text\")\n",
    "teams = []\n",
    "for team in scraped_teams:\n",
    "    teams.append(team.get_text())\n",
    "del teams[9:]\n",
    "first_team = soup.find('div', class_=\"rankings-block__banner--nationality\").get_text().replace('\\n', '')\n",
    "teams.insert(0, first_team)\n",
    "scraped_rating = soup.find_all('td', class_=\"table-body__cell rating\")\n",
    "rating = []\n",
    "for rate in scraped_rating:\n",
    "    rating.append(rate.get_text())\n",
    "del rating[9:]\n",
    "first_rating = soup.find('div', class_=\"rankings-block__banner--rating\").get_text()\n",
    "rating.insert(0, first_rating)\n",
    "rating\n",
    "data = pd.DataFrame()\n",
    "data['Player'] = players\n",
    "data['Team'] = teams\n",
    "data['Rating'] = rating\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9302da67",
   "metadata": {},
   "source": [
    "# 6) Write a python program to scrape cricket rankings from icc-cricket.com. You have to scrape:\n",
    "# a) Top 10 ODI teams in women’s cricket along with the records for matches, points and rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "118aab65",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup as bs\n",
    "import requests as rq\n",
    "import pandas as pd\n",
    "url = 'https://www.icc-cricket.com/rankings/womens/team-rankings/odi'\n",
    "page = rq.get(url)\n",
    "soup = bs(page.content, 'html.parser')\n",
    "scraped_teams = soup.find_all('span', class_=\"u-hide-phablet\")\n",
    "teams = []\n",
    "for team in scraped_teams:\n",
    "    teams.append(team.get_text())\n",
    "del teams[10:]\n",
    "matches = []\n",
    "scraped_matches = soup.find_all('td', class_=\"table-body__cell u-center-text\")\n",
    "for match in scraped_matches:\n",
    "    matches.append(match.get_text())\n",
    "del matches[1::2]\n",
    "del matches[9:]\n",
    "first_match = soup.find('td', class_=\"rankings-block__banner--matches\").get_text()\n",
    "matches.insert(0, first_match)\n",
    "points = []\n",
    "scraped_points = soup.find_all('td', class_=\"table-body__cell u-center-text\")\n",
    "for point in scraped_points:\n",
    "    points.append(point.get_text())\n",
    "del points[::2]\n",
    "del points[9:]\n",
    "first_point = soup.find('td', class_=\"rankings-block__banner--points\").get_text()\n",
    "points.insert(0, first_point)\n",
    "rating = []\n",
    "scraped_rating = soup.find_all('td', class_=\"table-body__cell u-text-right rating\")\n",
    "for rate in scraped_rating:\n",
    "    rating.append(rate.get_text())\n",
    "del rating[9:]\n",
    "first_rating = soup.find('td', class_=\"rankings-block__banner--rating u-text-right\").get_text().replace('\\n', '').strip(' ')\n",
    "rating.insert(0, first_rating)\n",
    "rating\n",
    "data = pd.DataFrame()\n",
    "data['Team'] = teams\n",
    "data['Matches'] = matches\n",
    "data['Points'] = points\n",
    "data['Rating'] = rating\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33d795fb",
   "metadata": {},
   "source": [
    "# b) Top 10 women’s ODI Batting players along with the records of their team and rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43a8417e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup as bs\n",
    "import requests as rq\n",
    "import pandas as pd\n",
    "\n",
    "url = 'https://www.icc-cricket.com/rankings/womens/player-rankings/odi/batting'\n",
    "page = rq.get(url)\n",
    "soup = bs(page.content, 'html.parser')\n",
    "scraped_players = soup.find_all('td', class_=\"table-body__cell rankings-table__name name\")\n",
    "players = []\n",
    "for player in scraped_players:\n",
    "    players.append(player.get_text().replace('\\n', ''))\n",
    "del players[9:]\n",
    "first_player = soup.find('div', class_=\"rankings-block__banner--name-large\").get_text()\n",
    "players.insert(0, first_player)\n",
    "scraped_teams = soup.find_all('span', class_=\"table-body__logo-text\")\n",
    "teams = []\n",
    "for team in scraped_teams:\n",
    "    teams.append(team.get_text())\n",
    "del teams[9:]\n",
    "first_team = soup.find('div', class_=\"rankings-block__banner--nationality\").get_text().replace('\\n', '')\n",
    "teams.insert(0, first_team)\n",
    "scraped_rating = soup.find_all('td', class_=\"table-body__cell rating\")\n",
    "rating = []\n",
    "for rate in scraped_rating:\n",
    "    rating.append(rate.get_text())\n",
    "del rating[9:]\n",
    "first_rating = soup.find('div', class_=\"rankings-block__banner--rating\").get_text()\n",
    "rating.insert(0, first_rating)\n",
    "rating\n",
    "data = pd.DataFrame()\n",
    "data['Player'] = players\n",
    "data['Team'] = teams\n",
    "data['Rating'] = rating\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b41dc08",
   "metadata": {},
   "source": [
    "# c) Top 10 women’s ODI all-rounder along with the records of their team and rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f5013e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup as bs\n",
    "import requests as rq\n",
    "import pandas as pd\n",
    "\n",
    "url = 'https://www.icc-cricket.com/rankings/womens/player-rankings/odi/all-rounder'\n",
    "page = rq.get(url)\n",
    "soup = bs(page.content, 'html.parser')\n",
    "scraped_players = soup.find_all('td', class_=\"table-body__cell rankings-table__name name\")\n",
    "players = []\n",
    "for player in scraped_players:\n",
    "    players.append(player.get_text().replace('\\n', ''))\n",
    "del players[9:]\n",
    "first_player = soup.find('div', class_=\"rankings-block__banner--name-large\").get_text()\n",
    "players.insert(0, first_player)\n",
    "scraped_teams = soup.find_all('span', class_=\"table-body__logo-text\")\n",
    "teams = []\n",
    "for team in scraped_teams:\n",
    "    teams.append(team.get_text())\n",
    "del teams[9:]\n",
    "first_team = soup.find('div', class_=\"rankings-block__banner--nationality\").get_text().replace('\\n', '')\n",
    "teams.insert(0, first_team)\n",
    "scraped_rating = soup.find_all('td', class_=\"table-body__cell rating\")\n",
    "rating = []\n",
    "for rate in scraped_rating:\n",
    "    rating.append(rate.get_text())\n",
    "del rating[9:]\n",
    "first_rating = soup.find('div', class_=\"rankings-block__banner--rating\").get_text()\n",
    "rating.insert(0, first_rating)\n",
    "rating\n",
    "data = pd.DataFrame()\n",
    "data['Player'] = players\n",
    "data['Team'] = teams\n",
    "data['Rating'] = rating\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bacab9b",
   "metadata": {},
   "source": [
    "# 7) Write a python program to scrape mentioned news details from                https://www.cnbc.com/world/?region=world :\n",
    " # i) Headline\n",
    "# ii) Time\n",
    "# iii) News Link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b01d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests as rq\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import pandas as pd\n",
    "\n",
    "url = 'https://www.cnbc.com/world/?region=world'\n",
    "page = rq.get(url)\n",
    "soup = bs(page.content, 'html.parser')\n",
    "news = soup.find_all('a', class_=\"LatestNews-headline\")\n",
    "latnews = []\n",
    "for i in news:\n",
    "    latnews.append(i.text)\n",
    "times = soup.find_all('time', class_=\"LatestNews-timestamp\")\n",
    "time = []\n",
    "for i in times:\n",
    "    time.append(i.text)\n",
    "links = soup.find_all('a', class_=\"LatestNews-headline\")\n",
    "link = []\n",
    "for i in links:\n",
    "    link.append(i['href'])\n",
    "data = pd.DataFrame()\n",
    "data['HeadLines'] = latnews\n",
    "data['Time'] = time\n",
    "data['News Link'] = link\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "191f1088",
   "metadata": {},
   "source": [
    "# 8) Write a python program to scrape the details of most downloaded articles        from AI in last 90 days. \n",
    "#   https://www.journals.elsevier.com/artificial-intelligence/most-downloaded-          articles\n",
    "#   Scrape below mentioned details :\n",
    "#   i) Paper Title \n",
    "#   ii) Authors\n",
    "#   iii) Published Date \n",
    "#   iv) Paper URL \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a0597e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup as bs\n",
    "import requests as rq\n",
    "import pandas as pd\n",
    "\n",
    "url = 'https://www.journals.elsevier.com/artificial-intelligence/most-downloaded-articles'\n",
    "page = rq.get(url)\n",
    "soup = bs(page.content, 'html.parser')\n",
    "scraped_titles = soup.find_all('h2', class_=\"sc-1qrq3sd-1 MKjKb sc-1nmom32-0 sc-1nmom32-1 hqhUYH ebTA-dR\")\n",
    "titles = []\n",
    "for title in scraped_titles:\n",
    "    titles.append(title.text)\n",
    "scraped_authors = soup.find_all('span', class_=\"sc-1w3fpd7-0 pgLAT\")\n",
    "authors = []\n",
    "for author in scraped_authors:\n",
    "    authors.append(author.text)\n",
    "scraped_dates = soup.find_all('span', class_=\"sc-1thf9ly-2 bKddwo\")\n",
    "dates = []\n",
    "for date in scraped_dates:\n",
    "    dates.append(date.find('span').text)\n",
    "scraped_urls = soup.find_all('li', class_=\"sc-9zxyh7-1 sc-9zxyh7-2 exAXfr jQmQZp\")\n",
    "urls = []\n",
    "for url in scraped_urls:\n",
    "    urls.append(url.find('a')['href'])\n",
    "data = pd.DataFrame()\n",
    "data['Paper Title'] = titles\n",
    "data['Authors'] = authors\n",
    "data['Published Date'] = dates\n",
    "data['Paper URL'] = urls\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ef8486d",
   "metadata": {},
   "source": [
    "# 9) Write a python program to scrape mentioned details from dineout.co.in :\n",
    "# i) Restaurant name\n",
    "# ii) Cuisine\n",
    "# iii) Location \n",
    "# iv) Ratings\n",
    "# v) Image URL\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb9d4789",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup as bs\n",
    "import requests as rq\n",
    "import pandas as pd\n",
    "\n",
    "url = 'https://www.dineout.co.in/delhi-restaurants/buffet-special'\n",
    "page = rq.get(url)\n",
    "soup = bs(page.content, 'html.parser')\n",
    "res_names = soup.find_all('div', class_=\"restnt-info cursor\")\n",
    "names = []\n",
    "for name in res_names:\n",
    "    names.append(name.find('a', class_=\"restnt-name ellipsis\").get_text())\n",
    "res_cuisines = soup.find_all('span', class_=\"double-line-ellipsis\")\n",
    "cuisines = []\n",
    "for cuisine in res_cuisines:\n",
    "    cuisines.append(cuisine.get_text().split('|')[1])\n",
    "res_locs = soup.find_all('div', class_=\"restnt-loc ellipsis\")\n",
    "locs = []\n",
    "for loc in res_locs:\n",
    "    locs.append(loc.get_text())\n",
    "res_ratings = soup.find_all('div', class_=\"restnt-rating rating-4\")\n",
    "ratings = []\n",
    "for rating in res_ratings:\n",
    "    ratings.append(rating.get_text())\n",
    "res_urls = soup.find_all('img', class_=\"no-img\")\n",
    "urls = []\n",
    "for url in res_urls:\n",
    "    urls.append(url[\"data-src\"])\n",
    "data = pd.DataFrame()\n",
    "data['Restaurant'] = names\n",
    "data['Cuisines'] = cuisines\n",
    "data['Location'] = locs\n",
    "data['Rating'] = ratings\n",
    "data['Image URL'] = urls\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "615fbe1c",
   "metadata": {},
   "source": [
    "# 10) Write a python program to scrape the details of top publications from Google Scholar from \n",
    "# https://scholar.google.com/citations?view_op=top_venues&hl=en\n",
    "# i) Rank \n",
    "# ii) Publication\n",
    "# iii) h5-index\n",
    "# iv) h5-median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38df86bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup as bs\n",
    "import requests as rq\n",
    "import pandas as pd\n",
    "\n",
    "url = 'https://scholar.google.com/citations?view_op=top_venues&hl=en'\n",
    "page = rq.get(url)\n",
    "soup = bs(page.content, 'html.parser')\n",
    "scr_ranks = soup.find_all('td', class_=\"gsc_mvt_p\")\n",
    "ranks = []\n",
    "for rank in scr_ranks:\n",
    "    ranks.append(rank.get_text())\n",
    "scr_publs = soup.find_all('td', class_=\"gsc_mvt_t\")\n",
    "publs = []\n",
    "for publ in scr_publs:\n",
    "    publs.append(publ.get_text())\n",
    "scr_inds = soup.find_all('a', class_=\"gs_ibl gsc_mp_anchor\")\n",
    "scr_inds\n",
    "index = []\n",
    "for ind in scr_inds:\n",
    "    index.append(ind.get_text())\n",
    "scr_meds = soup.find_all('span', class_=\"gs_ibl gsc_mp_anchor\")\n",
    "median = []\n",
    "for med in scr_meds:\n",
    "    median.append(med.text)\n",
    "data = pd.DataFrame()\n",
    "data['Rank'] = ranks\n",
    "data['Publication'] = publs\n",
    "data['h5-index'] = index\n",
    "data['h5-median'] = median\n",
    "data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
